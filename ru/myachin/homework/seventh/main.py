# ## Advanced pandas
# В задачах этого раздела нельзя использовать циклы. Задачи сложные, и в принципе их можно пропустить, но даже
# частичное продвижение позволит вам лучше разобраться в том, как работает `pandas`. Так что мы советуем по крайней
# мере попробовать.
# 
# ### Задача 1 (4 балла)
# В датафрейме `purchases` находится информация о покупках: кто, какого товара и сколько единиц купил.
# В датафрейме `goods` указана цена каждого товара. В датафрейме `discounts` указана скидка (в процентах) для
# некоторых покупателей. Пример:
#
# Вам необходимо написать функцию `totals(purchases, goods, discounts)`, которая возвращает датафрейм, в котором по
# строчкам записаны все клиенты, которые есть в `purchases`, по столбцам — все товары, которые есть в `goods`,
# на пересечении — сколько всего денег выручил магазин с данного клиента за данный товар. (Эту таблицу потом будет
# удобно использовать, чтобы быстро определить, сколько денег мы получили с каждого клиента и сколько денег получили
# с продажи каждого товара.)
#
# Например, для приведенных выше данных функция должна вернуть `pd.DataFrame` со следующим содержимым:
#
#    good     sweeties  chocolate  juice  lemons
#    client
#    Alice        54.0      18.90    0.0     0.0
#    Bob           0.0      33.25    0.0     0.0
#    Claudia       0.0       0.00   16.0     0.0#Z
#
# **Подсказка.** Вам скорее всего понадобятся методы `merge` (объединение двух таблиц), `fillna` (заполнение пропусков)
# и `pivot_table` (создание сводной таблицы). Один из методов решения этой задачи такой. Сначала объедините
# таблицу `purchases` с двумя другими таблицами таким образом, чтобы про каждую покупку знать, какова стоимость
# купленного товара и какова скидка покупателя для данной покупки; там, где скидка не определена, нужно добавить
# нули (это как раз можно сделать с помощью `fillna` — кстати, он может заполнять какие-то отдельные столбцы, для
# этого ему нужно передать словарь), затем нужно вычислить цену с учётом скидки и сумму, уплаченную за конкретный
# товар, а потом применить к результату `pivot_table`. Наконец, вам нужно добавить колонки для тех товаров, которые
# присутствуют в `goods`, но не упоминаются в покупках — это можно сделать с помощью `reindex`.
#
# Это непростая задача, но мы рекомендуем её сделать. Уверены, вам понравится результат!

def totals(purchases, goods, discounts):
    joined_df = purchases.merge(goods, how='left', left_on='item', right_on='good').merge(discounts, how='left').fillna(
        0)
    joined_df['total'] = joined_df['quantity'] * joined_df['price'] * ((100 - joined_df['discount']) / 100)
    df = joined_df.pivot_table(index='client', columns='good', values='total')
    return df.reindex(goods['good'], axis='columns').fillna(0)


# ### Задача 2 (5 баллов)
# 
# В датафрейме `grades` находятся оценки студентов, полученные ими за самостоятельные работы в классе.
#  Если студент не сдал работу, в соответствующей ячейке стоит `NaN`. В датафрейме `excuses` находится список различных
# причин, по которым данный студент мог не посетить занятие и не сдать соответствующую работу. Профессор
# МакГонагалл уважительной причиной считает только пропуск по болезни. Некоторые студенты настолько её боятся,
# что ходят на занятия и сдают работы, даже имея уважительную причину не ходить.
# 
# В конце года профессор МакГонагалл выставляет итоговые оценки путём вычисления среднего от всех полученных оценок.
# Если студент пропустил работу по неуважительной причине, то ему или ей за неё выставляется 0, если же пропуск
# был по уважительной причине, то эта работа просто не учитывается при вычислении среднего (как будто такого занятия
# для данного студента просто не было).
# 
# Например, рассмотрим такие данные.
# Здесь уважительной причиной МакГонагалл посчитает только те, в описании которых есть слово `ill`. Гермиона не
# сдала работу 2017-02-12 по болезни и эта работа будет исключена при подсчёте. А на 2017-02-26 у неё нет никакой
# уважительной причины и за неё она получит 0. Итоговая оценка Гермионы будет (5 + 7 + 0) / 3 = 4.
# 
# У Рона нет уважительных причин пропуска, поэтому он получит (2 + 0 + 0 + 4) / 4 = 1.5.
# 
# Написать функцию, `final_grades(grades, excuses)`, которая бы принимала на вход два указанных датафрейма и
# возвращала `pd.Series`, в котором индексами были имена студентов (в том же порядке, как в `grades`), а
# значениями — итоговые оценки. Для примера выше функция должна вернуть `pd.Series`, имеющий вид:
# 
#     Hermione    4.0
#     Ron         1.5
#     dtype: float64
# 
# **Замечание.** Задачу можно и нужно решить без циклов и `if`ов, но, возможно, по первому времени придётся поломать
# голову. (Автор её решал примерно полчаса.) Если ничего не будет получаться — обращайтесь за подсказками. Пока что
# скажем, что задачу можно решать с помощью `pivot_table` и `fillna` — последний может принимать на вход
# датафрейм и заполнять незаполненные ячейки исходного датафрейма ячейками переданного. Вам также может
# пригодиться `reindex`. Чтобы проверить наличие подстроки в строках, лежащих в столбце `pandas`, нужно
# использовать `.str.contains()`. Впрочем, вероятно, есть и другие способы решать эта задачу, и тогда вам пригодится
# что-нибудь другое.

def final_grades(grades, excuses):
    print("don't complete")


# ## Веб-скреппинг
# 
# В задачах этого раздела можно и нужно использовать библиотеки `requests` и `bs4`. Здесь также нет ограничения на
# использование циклов и `if`'ов.

# ### Задача 3 (2 балла)
# Написать функцию `any_news_about_harry(url)`, принимающую на вход адрес веб-страницы `url`, загружающую эту
# веб-страницу и проверяющую, встречается ли в ней слово `Harry` (с большой буквы). Функция должна
# возвращать `True`, если встречается, и `False` в противном случае. Также функция должна возвращать `False`,
# если страницу не удалось открыть (например, была получена ошибка *404 Not Found*.)
# 
# **Подсказка.** Чтобы загрузить страницу, нужно использовать библиотеку `requests`:
# 
#     import requests
#     r = requests.get(url)
# 
# Содержимое страницы затем окажется в `r.text`. Проверить, что запрос увенчался успехом, можно так:
# 
#     if r:
#         # увенчался успехом

import requests


def any_news_about_harry(url):
    r = requests.get(url)
    if not r:
        return False

    if "Harry" in r.text:
        return True

    return False


# ### Задача 4 (1 балл)
# Написать функцию `get_strong(html)`, принимающую на вход html-страницу в виде длинной строки, записанной в
# переменную `html`, и возвращающую строчку, содержащуюся в первом теге `strong`.
# 
# Примеры см. в тестах.
# 
# **Подсказка.** Вы можете создать объект `BeautifulSoup`, передав ему строку с html в качестве параметра. Например:
# 
# ```python
# from bs4 import BeautifulSoup
# page = BeautifulSoup("<html><body><p>Hello</p></body></html>", "html.parser")
# print(page.p)
# ```


from bs4 import BeautifulSoup


def get_strong(html):
    page = BeautifulSoup(html, "lxml");
    return page.find("strong").text


# ### Задача 5 (1 балл)
# Для вставки картинок в HTML используется тег `<img>`, содержащий параметр `src` — адрес файла с картинкой.
# Например, `<img src="https://upload.wikimedia.org/wikipedia/commons/b/bd/Struthio_camelus_portrait_
# Whipsnade_Zoo.jpg"/>`. Написать функцию `all_images_src(html)`, принимающую на вход длинную строчку с
# HTML-документом, а возвращающую список адресов всех картинок, встречающихся в этом документе (в том порядке, в
# котором они встречаются в документе).
# 
# **Подсказка.** Для обращения к атрибутам тега нужно использовать квадратные скобки, как если бы тег был словарём.

def all_images_src(html):
    page = BeautifulSoup(html, "lxml");
    images = page.findAll("img")
    result = []
    for image in images:
        result.append(image["src"])

    return result


# ### Задача 6 (2 балла)
# Написать функцию `get_all_headings(url)`, принимающую на вход адрес страницы в Википедии и возвращающую список,
# состоящий из названий разделов статьи (в порядке появления в статье). Если такой страницы не существует, функция
# должна вернуть список, состоящей из строки `"Not found"`.
# 
# **Подсказка.** С помощью функции вашего браузера *inspect element* или аналогичной, исследуйте, в каких тегах и с
# какими классами находятся искомые заголовки. Не во всех страницах есть содержание! Например, ваш код должен
# корректно обрабатывать
# [эту страницу](https://ru.wikipedia.org/w/index.php?title=User%3AIlya_Voyager%2Fsandbox%2Fh2test&oldid=75055744).

def get_all_headings(url):
    response = requests.get(url)
    result = []
    if not response:
        result.append("Not found")

    page = BeautifulSoup(response.text, "lxml")
    for h2 in page.findAll("h2"):
        span = h2.find("span", class_="mw-headline")
        if span is not None:
            result.append(span.text)

    return result


# ### Задача 7 (4 балла)
# 
# Написать функцию `city_tz(name)`, принимающую на вход название города и возвращающую строку, содержащую часовой
# пояс, действующий в этом городе (например, `'UTC+3'`), согласно данным русской Википедии. Если такого города
# Википедия не знает, или если у города не указан часовой пояс `None`.
# 
# Предполагается, что вы будете решать эту задачу, обрабатывая HTML-код веб-страницы, а не исходный код статей, и не
# будете пользоваться сторонними библиотеками (кроме `urllib`, `requests`, `BeautifulSoup`).
# 
# **Подсказка.** Как сформировать адрес страницы, зная название статьи, можно подсмотреть в тесте к задаче 6.
# Впрочем, можно передать адрес страницы напрямую в `requests.get`, см.
# [официальную документацию](http://docs.python-requests.org/en/latest/user/quickstart/#passing-parameters-in-urls).

def city_tz(name):
    response = requests.get("https://ru.wikipedia.org/w/index.php?title=" + name)
    if not response:
        return None

    page = BeautifulSoup(response.text, "lxml")
    return page.find("a", title="Часовой пояс").parent.parent.find("span").find("a").text
